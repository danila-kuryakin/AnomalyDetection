{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1FFvc5PsEbADaDJbZ_M0jm38hosFYoD7R","authorship_tag":"ABX9TyPvZ4NG1aQ9DtE25jCYXaLm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"7uNlUCVjDi_j","executionInfo":{"status":"ok","timestamp":1668279467926,"user_tz":-180,"elapsed":7348,"user":{"displayName":"Данила Курякин","userId":"05471251660353855023"}}},"outputs":[],"source":["import os\n","if not os.path.isdir('Data'):\n","    import requests\n","\n","    os.mkdir('Data')\n","\n","    url = 'https://www.dropbox.com/s/d939ucy3bumt9hb/data_train.csv?dl=1'\n","    r = requests.get(url, allow_redirects=True)\n","    open('Data/data_train.csv', 'wb').write(r.content)\n","\n","    url = 'https://www.dropbox.com/s/6ghexq1uijis473/data_val.csv?dl=1'\n","    r = requests.get(url, allow_redirects=True)\n","    open('Data/data_val.csv', 'wb').write(r.content)\n","\n","    url = 'https://www.dropbox.com/s/py8um99gnjjwcub/data_test.csv?dl=1'\n","    r = requests.get(url, allow_redirects=True)\n","    open('Data/data_test.csv', 'wb').write(r.content)"]},{"cell_type":"code","source":["pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iLjP2xVuEHpP","executionInfo":{"status":"ok","timestamp":1667812357888,"user_tz":-180,"elapsed":4579,"user":{"displayName":"Данила Курякин","userId":"05471251660353855023"}},"outputId":"cf5c2955-d9c1-4699-95c7-3c2680708966"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.18.0\n"]}]},{"cell_type":"code","source":["pip install image-classifiers==1.0.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wLvHRBI9EQ_4","executionInfo":{"status":"ok","timestamp":1667812361486,"user_tz":-180,"elapsed":3601,"user":{"displayName":"Данила Курякин","userId":"05471251660353855023"}},"outputId":"28a3ccfb-49d6-401b-8994-578419034a6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting image-classifiers==1.0.0\n","  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n","Collecting keras-applications<=1.0.8,>=1.0.7\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 2.3 MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (3.1.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.21.6)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.5.2)\n","Installing collected packages: keras-applications, image-classifiers\n","Successfully installed image-classifiers-1.0.0 keras-applications-1.0.8\n"]}]},{"cell_type":"code","source":["from abc import ABC\n","\n","import os\n","import random\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from shutil import copyfile\n","import csv\n","from classification_models.tfkeras import Classifiers\n","import gc\n","\n","from abc import ABC\n","import tensorflow as tf\n"],"metadata":{"id":"bXU7hSXZIgZL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_data(filename):\n","    csvfile = open(filename)\n","    reader = csv.reader(csvfile, delimiter=';')\n","    next(reader)\n","    data = []\n","    for row in reader:\n","        item = [row[0], row[2:]]\n","        data.append(item)\n","    images = np.zeros((len(data), 48, 48, 1), dtype='float32')\n","    labels = np.zeros((len(data)), dtype='float32')\n","    labels_full = np.zeros(shape=(len(data), 7), dtype='float32')\n","    for i in range(len(data)):\n","        images[i, :, :, :] = np.array(data[i][1]).reshape((48, 48, 1))\n","        labels[i] = np.array(data[i][0]).astype('float32')\n","        labels_full[i, int(labels[i])] = 1\n","    return images, labels_full\n","\n","\n","def etl_data(path):\n","    images, labels = get_data(path)\n","    images = tf.image.resize(images=images, size=(224, 224), method='bilinear').numpy()\n","    imagesRGB = np.zeros(shape=(images.shape[0], 224, 224, 3), dtype='float32')\n","    for i in range(images.shape[0]):\n","        imagesRGB[i, :, :, :] = tf.image.grayscale_to_rgb(tf.convert_to_tensor(images[i, :, :, :])).numpy()\n","    return imagesRGB, labels"],"metadata":{"id":"l2G5n8nZIiQ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class cb3(tf.keras.callbacks.Callback):\n","    def __init__(self, x, y):\n","        self.x = x\n","        self.y = y\n","        self.reports = []\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        report = tf.keras.metrics.CategoricalAccuracy()(self.y, self.model.predict(self.x)).numpy()\n","        self.reports.append(report)\n","        print(\"Test Accuracy\", report)\n","        print(\"\")\n","        return"],"metadata":{"id":"jkEkuoWrInIZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def augment(images, params):\n","\n","    y = images\n","\n","    if params['flip']:\n","        y = tf.image.flip_left_right(image=y)\n","\n","    if params['zoom'] > 0 and params['zoom'] < 1:\n","        y = tf.image.central_crop(image=y,\n","                                  central_fraction=params['zoom'])\n","        y = tf.image.resize(images=y,\n","                            size=[images.shape[1], images.shape[2]],\n","                            method='bilinear',\n","                            preserve_aspect_ratio=False)\n","\n","    if params['shift_h'] != 0 or params['shift_v'] != 0:\n","        y = tfa.image.translate(images=y,\n","                                translations=[params['shift_h'], params['shift_v']],\n","                                interpolation='bilinear',\n","                                fill_mode='nearest')\n","    if params['rot'] != 0:\n","        y = tfa.image.rotate(images=y,\n","                             angles=params['rot'],\n","                             interpolation='bilinear',\n","                             fill_mode='nearest')\n","\n","    return y\n","\n","\n","def TTA_Inference(model, x):\n","    pred_test = model.predict(x)\n","    zooms = [1]  # 2\n","    rotations = [0, 0.4, -0.4]  # 5\n","    shifts_h = [0, 10, -10]  # 3\n","    shifts_v = [0, 10, -10]  # 3\n","    flips = [False, True]  # 2\n","\n","    default_prediction_weight = 3\n","    count = default_prediction_weight\n","    predictions = default_prediction_weight*pred_test\n","\n","    for i1 in range(len(zooms)):\n","        for i2 in range(len(rotations)):\n","            for i3 in range(len(shifts_h)):\n","                for i4 in range(len(shifts_v)):\n","                    for i5 in range(len(flips)):\n","                        params = {'zoom': zooms[i1],\n","                                  'rot': rotations[i2],\n","                                  'shift_h': shifts_h[i3],\n","                                  'shift_v': shifts_v[i4],\n","                                  'flip': flips[i5]}\n","                        if params['zoom'] < 1 or params['rot'] != 0 or params['shift_h'] != 0 or params['shift_v'] != 0 or params['flip']:\n","\n","                            count = count + 1\n","                            d = augment(x, params)\n","                            preds = model.predict(d, batch_size=128)\n","                            predictions = predictions + preds\n","                            del d\n","                            del preds\n","                            del params\n","                            gc.collect()\n","                            gc.collect()\n","                            gc.collect()\n","\n","    Params = [[0.9, 0, 0, 0, False],\n","              [0.9, 0, 0, 0, True],\n","              [0.9, 0.15, 0, 0, False],\n","              [0.9, 0.15, 0, 0, True],\n","              [0.9, -0.15, 0, 0, False],\n","              [0.9, -0.15, 0, 0, True]]\n","\n","    for i in range(len(Params)):\n","        params = {'zoom': Params[i][0],\n","                  'rot': Params[i][1],\n","                  'shift_h': Params[i][2],\n","                  'shift_v': Params[i][3],\n","                  'flip': Params[i][4]}\n","        count = count + 1\n","        d = augment(x, params)\n","        preds = model.predict(d, batch_size=128)\n","        predictions = predictions + preds\n","\n","        del d\n","        del preds\n","        del params\n","        gc.collect()\n","        gc.collect()\n","        gc.collect()\n","\n","    predictions = predictions / count\n","    return predictions\n","\n","\n","def Check_Unique(x):\n","    lose = 0\n","    for i in range(x.shape[0]):\n","        if sum(x[i, :] == x[i, :].max()) > 1:\n","            lose = lose + 1\n","    return lose"],"metadata":{"id":"xc0-8evdD96f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import zipfile\n","if not os.path.isdir('Data_Images'):\n","  with zipfile.ZipFile(\"/content/drive/MyDrive/Meta_dataset/Training.zip\", 'r') as zip_ref:\n","        zip_ref.extractall(\"Data_Images\")"],"metadata":{"id":"G3g8Zy0BZjYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# rm -R /content/Data_Images"],"metadata":{"id":"doeWAB-sayG_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tf.__version__)\n","\n","\n","# resolution^2 deve essere divisibile per num_heads\n","class LHC_Module(tf.keras.layers.Layer):\n","    def __init__(self, pool_size, head_emb_dim, num_heads, num_channels, resolution, kernel_size, norm_c, name):\n","        super(LHC_Module, self).__init__()\n","        self.pool_size = pool_size\n","        self.head_emb_dim = head_emb_dim\n","        self.num_heads = num_heads\n","        self.num_channels = num_channels\n","        self.resolution = resolution\n","        self.kernel_size = kernel_size\n","        self.norm_c = norm_c\n","\n","        self.Poolq = tf.keras.layers.AvgPool2D(pool_size=(self.pool_size, self.pool_size),\n","                                               strides=(1, 1),\n","                                               padding='same')\n","        self.Poolk = tf.keras.layers.MaxPool2D(pool_size=(self.pool_size, self.pool_size),\n","                                               strides=(1, 1),\n","                                               padding='same')\n","\n","        self.Wqk = [tf.keras.layers.Dense(units=self.head_emb_dim, activation='linear') for _ in range(self.num_heads)]\n","\n","        self.Wp = tf.keras.layers.Dense(units=self.num_channels, activation='sigmoid')\n","\n","        self.Wv = tf.keras.layers.Conv2D(filters=self.num_channels,\n","                                         kernel_size=self.kernel_size,\n","                                         strides=(1, 1),\n","                                         padding='same',\n","                                         activation='linear')\n","        self.Poolv = tf.keras.layers.AvgPool2D(pool_size=(3, 3),\n","                                               strides=(1, 1),\n","                                               padding='same')\n","\n","        self.sum = tf.keras.layers.Add()\n","\n","        self.Name_1_ = 'LHC_1_'+name\n","\n","    def VectScaledDotProdAttention(self, query, key, value):\n","        scores = tf.linalg.matmul(query, key, transpose_b=True)  # (batch_size, num_heads, num_channels, num_channels)\n","        scores_p = tf.math.reduce_mean(scores, axis=3)  # (batch_size, num_heads, num_channels)\n","        scores_p = self.Wp(scores_p)  # (batch_size, num_heads, num_channels)\n","        scores_p = tf.expand_dims(scores_p, axis=-1)  # (batch_size, num_heads, num_channels, 1)\n","        norm_scores = tf.math.divide(scores, tf.math.pow(tf.dtypes.cast(key.shape[3], tf.float32), self.norm_c + scores_p))  # (batch_size, num_heads, num_channels, num_channels)\n","        weights = tf.nn.softmax(norm_scores, axis=3)  # (batch_size, num_heads, num_channels, num_channels)\n","        attentions = tf.linalg.matmul(weights, value)  # (batch_size, num_heads, num_channels, head_res_dim)\n","        return attentions\n","\n","    def call(self, x):\n","        batch_size = tf.shape(x)[0]\n","        num_channels = self.num_channels\n","        resolution = self.resolution\n","        head_res_dim = (resolution * resolution) // self.num_heads\n","\n","        query = x  # (batch_size, resolution, resolution, num_channels)\n","        query = self.Poolq(query)  # (batch_size, resolution, resolution, num_channels)\n","        query = tf.reshape(query, shape=(batch_size, resolution * resolution, num_channels))  # (batch_size, resolution^2, num_channels)\n","        query = tf.transpose(query, perm=[0, 2, 1])  # (batch_size, num_channels, resolution^2)\n","        query = tf.reshape(query, shape=(batch_size, num_channels, self.num_heads, head_res_dim))  # (batch_size, num_channels, num_heads, head_res_dim)\n","        query = tf.transpose(query, perm=[0, 2, 1, 3])  # (batch_size, num_heads, num_channels, head_res_dim)\n","        q = [None] * self.num_heads\n","        for i in range(self.num_heads):\n","            q[i] = self.Wqk[i](query[:, i, :, :])  # (batch_size, num_channels, head_emb_dim)\n","            q[i] = tf.expand_dims(q[i], axis=1)  # (batch_size, 1, num_channels, head_emb_dim)\n","        query = tf.concat(q, axis=1)  # (batch_size, num_heads, num_channels, head_emb_dim)\n","\n","        key = x  # (batch_size, resolution, resolution, num_channels)\n","        key = self.Poolk(key)  # (batch_size, resolution, resolution, num_channels)\n","        key = tf.reshape(key, shape=(batch_size, resolution * resolution, num_channels))  # (batch_size, resolution^2, num_channels)\n","        key = tf.transpose(key, perm=[0, 2, 1])  # (batch_size, num_channels, resolution^2)\n","        key = tf.reshape(key, shape=(batch_size, num_channels, self.num_heads, head_res_dim))  # (batch_size, num_channels, num_heads, head_res_dim)\n","        key = tf.transpose(key, perm=[0, 2, 1, 3])  # (batch_size, num_heads, num_channels, head_res_dim)\n","        k = [None] * self.num_heads\n","        for i in range(self.num_heads):\n","            k[i] = self.Wqk[i](key[:, i, :, :])  # (batch_size, num_channels, head_emb_dim)\n","            k[i] = tf.expand_dims(k[i], axis=1)  # (batch_size, 1, num_channels, head_emb_dim)\n","        key = tf.concat(k, axis=1)  # (batch_size, num_heads, num_channels, head_emb_dim)\n","\n","        value = self.Wv(x)  # (batch_size, resolution, resolution, num_channels)\n","        value = self.Poolv(value)  # (batch_size, resolution, resolution, num_channels)\n","        value = tf.reshape(value, shape=(batch_size, resolution * resolution, num_channels))  # (batch_size, resolution^2, num_channels)\n","        value = tf.transpose(value, perm=[0, 2, 1])  # (batch_size, num_channels, resolution^2)\n","        value = tf.reshape(value, shape=(batch_size, num_channels, self.num_heads, head_res_dim))  # (batch_size, num_channels, num_heads, head_res_dim)\n","        value = tf.transpose(value, perm=[0, 2, 1, 3])  # (batch_size, num_heads, num_channels, head_res_dim)\n","\n","        attentions = self.VectScaledDotProdAttention(query, key, value)  # (batch_size, num_heads, num_channels, head_res_dim)\n","\n","        attentions = tf.transpose(attentions, perm=[0, 2, 1, 3])  # (batch_size, num_channels, num_heads, head_res_dim)\n","        attention = tf.reshape(attentions, shape=(batch_size, num_channels, resolution * resolution))  # (batch_size, num_channels, resolution^2)\n","\n","        attention = tf.transpose(attention, perm=[0, 2, 1])  # (batch_size, resolution^2, num_channels)\n","        attention = tf.reshape(attention, shape=(batch_size, resolution, resolution, num_channels))  # (batch_size, resolution, resolution, num_channels)\n","\n","        out = self.sum([x, attention])  # (batch_size, resolution, resolution, num_channels)\n","\n","        return out\n","\n","\n","class LHCResBlockSmall(tf.keras.Model, ABC):\n","    def __init__(self, filters, kernels, strides, identity, resolution, att_num_channel, num_heads, att_embed_dim, att_kernel_size, pool_size, norm_c, name):\n","        super(LHCResBlockSmall, self).__init__(name='LHCResBlockSmall')\n","        self.Identity = identity\n","\n","        self.bn1 = tf.keras.layers.BatchNormalization(epsilon=2e-05, name=name+\"_BN1\")\n","        self.relu1 = tf.keras.layers.Activation(activation='relu', name=name+\"_Relu1\")\n","        self.pad1 = tf.keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name+'_Padding1')\n","        self.conv1 = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernels[0], strides=strides[0], padding='valid', activation='linear', use_bias=False, name=name+'_Conv1')\n","\n","        self.bn2 = tf.keras.layers.BatchNormalization(epsilon=2e-05, name=name+\"_BN2\")\n","        self.relu2 = tf.keras.layers.Activation(activation='relu', name=name+\"_Relu2\")\n","        self.pad2 = tf.keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name+'_Padding2')\n","        self.conv2 = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernels[1], strides=strides[1], padding='valid', activation='linear', use_bias=False, name=name+'_Conv2')\n","\n","        if self.Identity:\n","            self.convId = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernels[2], strides=strides[2], padding='valid', activation='linear', use_bias=False, name=name+'_ConvId')\n","\n","        self.LHC_Module = LHC_Module(pool_size=pool_size,\n","                                     resolution=resolution,\n","                                     num_channels=att_num_channel,\n","                                     num_heads=num_heads,\n","                                     head_emb_dim=att_embed_dim,\n","                                     kernel_size=att_kernel_size,\n","                                     norm_c=norm_c,\n","                                     name=name)\n","\n","        self.add = tf.keras.layers.Add()\n","\n","    def call(self, x):\n","        if self.Identity:\n","            y = self.bn1(x)\n","            y = self.relu1(y)\n","            xb = y\n","            y = self.pad1(y)\n","            y = self.conv1(y)\n","\n","            y = self.bn2(y)\n","            y = self.relu2(y)\n","            y = self.pad2(y)\n","            y = self.conv2(y)\n","\n","            y2 = self.convId(xb)\n","\n","            y = self.add([y, y2])\n","\n","            y = self.LHC_Module(y)\n","\n","            return y\n","        else:\n","            y = self.bn1(x)\n","            y = self.relu1(y)\n","            y = self.pad1(y)\n","            y = self.conv1(y)\n","\n","            y = self.bn2(y)\n","            y = self.relu2(y)\n","            y = self.pad2(y)\n","            y = self.conv2(y)\n","\n","            y = self.add([y, x])\n","\n","            y = self.LHC_Module(y)\n","\n","            return y\n","\n","    def import_w(self, layers):\n","        for i in range(len(layers)):\n","            for j in range(len(layers[i].weights)):\n","                self.layers[i].weights[j].assign(layers[i].weights[j])\n","\n","\n","class LHCResBlockSmall0(tf.keras.Model, ABC):\n","    def __init__(self, input_shape, resolution, att_num_channel, num_heads, att_embed_dim, att_kernel_size, pool_size, norm_c):\n","        super(LHCResBlockSmall0, self).__init__(name='LHCResBlockSmall0')\n","\n","        self.Input = tf.keras.layers.InputLayer(input_shape=input_shape)\n","\n","        self.bn1 = tf.keras.layers.BatchNormalization(epsilon=2e-05, scale=False, name='Block0_BN1')\n","        self.pad1 = tf.keras.layers.ZeroPadding2D(padding=((3, 3), (3, 3)), name='Block0_Padding1')\n","        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='valid', activation='linear', use_bias=False, name='Block0_Conv1')\n","        self.bn2 = tf.keras.layers.BatchNormalization(epsilon=2e-05, name='Block0_BN2')\n","        self.relu1 = tf.keras.layers.Activation(activation='relu', name='Block0_Relu1')\n","        self.pad2 = tf.keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='Block0_Padding2')\n","        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2), name='Block0_MaxPool1')\n","        self.LHC_Module = LHC_Module(pool_size=pool_size,\n","                                     resolution=resolution,\n","                                     num_channels=att_num_channel,\n","                                     num_heads=num_heads,\n","                                     head_emb_dim=att_embed_dim,\n","                                     kernel_size=att_kernel_size,\n","                                     norm_c=norm_c,\n","                                     name='Module_0')\n","\n","    def call(self, x):\n","        x1 = self.Input(x)\n","        x1 = self.bn1(x1)\n","        x1 = self.pad1(x1)\n","        x1 = self.conv1(x1)\n","        x1 = self.bn2(x1)\n","        x1 = self.relu1(x1)\n","        x1 = self.pad2(x1)\n","        x1 = self.pool1(x1)\n","\n","        x1 = self.LHC_Module(x1)\n","        return x1\n","\n","    def import_w(self, layers):\n","        for i in range(len(layers)):\n","            for j in range(len(layers[i].weights)):\n","                self.layers[i].weights[j].assign(layers[i].weights[j])\n","\n","\n","class ResBlockSmall(tf.keras.Model, ABC):\n","    def __init__(self, filters, kernels, strides, identity, name):\n","        super(ResBlockSmall, self).__init__(name='ResBlockSmall')\n","        self.Identity = identity\n","\n","        self.bn1 = tf.keras.layers.BatchNormalization(epsilon=2e-05, name=name+\"_BN1\")\n","        self.relu1 = tf.keras.layers.Activation(activation='relu', name=name+\"_Relu1\")\n","        self.pad1 = tf.keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name+'_Padding1')\n","        self.conv1 = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernels[0], strides=strides[0], padding='valid', activation='linear', use_bias=False, name=name+'_Conv1')\n","\n","        self.bn2 = tf.keras.layers.BatchNormalization(epsilon=2e-05, name=name+\"_BN2\")\n","        self.relu2 = tf.keras.layers.Activation(activation='relu', name=name+\"_Relu2\")\n","        self.pad2 = tf.keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name+'_Padding2')\n","        self.conv2 = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernels[1], strides=strides[1], padding='valid', activation='linear', use_bias=False, name=name+'_Conv2')\n","\n","        if self.Identity:\n","            self.convId = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernels[2], strides=strides[2], padding='valid', activation='linear', use_bias=False, name=name+'_ConvId')\n","\n","        self.add = tf.keras.layers.Add()\n","\n","    def call(self, x):\n","        if self.Identity:\n","            y = self.bn1(x)\n","            y = self.relu1(y)\n","            xb = y\n","            y = self.pad1(y)\n","            y = self.conv1(y)\n","\n","            y = self.bn2(y)\n","            y = self.relu2(y)\n","            y = self.pad2(y)\n","            y = self.conv2(y)\n","\n","            y2 = self.convId(xb)\n","\n","            y = self.add([y, y2])\n","            return y\n","        else:\n","            y = self.bn1(x)\n","            y = self.relu1(y)\n","            y = self.pad1(y)\n","            y = self.conv1(y)\n","\n","            y = self.bn2(y)\n","            y = self.relu2(y)\n","            y = self.pad2(y)\n","            y = self.conv2(y)\n","\n","            y = self.add([y, x])\n","            return y\n","\n","    def import_w(self, layers):\n","        for i in range(len(layers)):\n","            for j in range(len(layers[i].weights)):\n","                self.layers[i].weights[j].assign(layers[i].weights[j])\n","\n","\n","class LHC_ResNet34(tf.keras.Model, ABC):\n","    def __init__(self, input_shape, num_classes, att_params):\n","        super(LHC_ResNet34, self).__init__(name='LHC_ResNet34')\n","\n","        self.Input = tf.keras.layers.InputLayer(input_shape=input_shape)\n","\n","        self.conv1 = LHCResBlockSmall0(input_shape=input_shape,\n","                                       resolution=56,\n","                                       att_num_channel=64,\n","                                       num_heads=att_params['num_heads'][0],\n","                                       att_embed_dim=att_params['att_embed_dim'][0],\n","                                       att_kernel_size=att_params['kernel_size'][0],\n","                                       pool_size=att_params['pool_size'][0],\n","                                       norm_c=att_params['norm_c'][0])\n","\n","        self.conv2_1 = ResBlockSmall(filters=64, kernels=((3, 3), (3, 3), (1, 1)), strides=((1, 1), (1, 1), (1, 1)), identity=True, name='stage1_unit1')\n","        self.conv2_2 = ResBlockSmall(filters=64, kernels=((3, 3), (3, 3), (1, 1)), strides=((1, 1), (1, 1), (1, 1)), identity=False, name='stage1_unit2')\n","        self.conv2_3 = LHCResBlockSmall(filters=64,\n","                                        kernels=((3, 3), (3, 3), (1, 1)),\n","                                        strides=((1, 1), (1, 1), (1, 1)),\n","                                        identity=False,\n","                                        resolution=56,\n","                                        att_num_channel=64,\n","                                        num_heads=att_params['num_heads'][1],\n","                                        att_embed_dim=att_params['att_embed_dim'][1],\n","                                        att_kernel_size=att_params['kernel_size'][1],\n","                                        pool_size=att_params['pool_size'][1],\n","                                        norm_c=att_params['norm_c'][1],\n","                                        name='stage1_unit3')\n","\n","        self.conv3_1 = ResBlockSmall(filters=128, kernels=((3, 3), (3, 3), (1, 1)), strides=((2, 2), (1, 1), (2, 2)), identity=True, name='stage2_unit1')\n","        self.conv3_2 = ResBlockSmall(filters=128, kernels=((3, 3), (3, 3), (1, 1)), strides=((1, 1), (1, 1), (1, 1)), identity=False, name='stage2_unit2')\n","        self.conv3_3 = ResBlockSmall(filters=128, kernels=((3, 3), (3, 3), (1, 1)), strides=((1, 1), (1, 1), (1, 1)), identity=False, name='stage2_unit3')\n","        self.conv3_4 = LHCResBlockSmall(filters=128,\n","                                        kernels=((3, 3), (3, 3), (1, 1)),\n","                                        strides=((1, 1), (1, 1), (1, 1)),\n","                                        identity=False,\n","                                        resolution=28,\n","                                        att_num_channel=128,\n","                                        num_heads=att_params['num_heads'][2],\n","                                        att_embed_dim=att_params['att_embed_dim'][2],\n","                                        att_kernel_size=att_params['kernel_size'][2],\n","                                        pool_size=att_params['pool_size'][2],\n","                                        norm_c=att_params['norm_c'][2],\n","                                        name='stage2_unit4')\n","\n","        self.conv4_1 = ResBlockSmall(filters=256, kernels=((3, 3), (3, 3), (1, 1)), strides=((2, 2), (1, 1), (2, 2)), identity=True, name='stage3_unit1')\n","        self.conv4_2 = ResBlockSmall(filters=256, kernels=((3, 3), (3, 3), (1, 1)), strides=((1, 1), (1, 1), (1, 1)), identity=False, name='stage3_unit2')\n","        self.conv4_3 = ResBlockSmall(filters=256, kernels=((3, 3), (3, 3), (1, 1)), strides=((1, 1), (1, 1), (1, 1)), identity=False, name='stage3_unit3')\n","        self.conv4_4 = ResBlockSmall(filters=256, kernels=((3, 3), (3, 3), (1, 1)), strides=((1, 1), (1, 1), (1, 1)), identity=False, name='stage3_unit4')\n","        self.conv4_5 = ResBlockSmall(filters=256, kernels=((3, 3), (3, 3), (1, 1)), strides=((1, 1), (1, 1), (1, 1)), identity=False, name='stage3_unit5')\n","        self.conv4_6 = LHCResBlockSmall(filters=256,\n","                                        kernels=((3, 3), (3, 3), (1, 1)),\n","                                        strides=((1, 1), (1, 1), (1, 1)),\n","                                        identity=False,\n","                                        resolution=14,\n","                                        att_num_channel=256,\n","                                        num_heads=att_params['num_heads'][3],\n","                                        att_embed_dim=att_params['att_embed_dim'][3],\n","                                        att_kernel_size=att_params['kernel_size'][3],\n","                                        pool_size=att_params['pool_size'][3],\n","                                        norm_c=att_params['norm_c'][3],\n","                                        name='stage3_unit6')\n","\n","        self.conv5_1 = ResBlockSmall(filters=512, kernels=((3, 3), (3, 3), (1, 1)), strides=((2, 2), (1, 1), (2, 2)),  identity=True, name='stage4_unit1')\n","        self.conv5_2 = ResBlockSmall(filters=512, kernels=((3, 3), (3, 3), (1, 1)), strides=((1, 1), (1, 1), (1, 1)),  identity=False, name='stage4_unit2')\n","        self.conv5_3 = LHCResBlockSmall(filters=512,\n","                                        kernels=((3, 3), (3, 3), (1, 1)),\n","                                        strides=((1, 1), (1, 1), (1, 1)),\n","                                        identity=False,\n","                                        resolution=7,\n","                                        att_num_channel=512,\n","                                        num_heads=att_params['num_heads'][4],\n","                                        att_embed_dim=att_params['att_embed_dim'][4],\n","                                        att_kernel_size=att_params['kernel_size'][4],\n","                                        pool_size=att_params['pool_size'][4],\n","                                        norm_c=att_params['norm_c'][4],\n","                                        name='stage4_unit3')\n","\n","        self.bn = tf.keras.layers.BatchNormalization(epsilon=2e-05, name='bn')\n","        self.relu = tf.keras.layers.Activation(activation='relu', name='relu')\n","\n","        self.pool = tf.keras.layers.GlobalAveragePooling2D()\n","\n","        self.fc1 = tf.keras.layers.Dense(units=4096, activation='relu')\n","        self.dp1 = tf.keras.layers.Dropout(0.4)\n","        self.fc2 = tf.keras.layers.Dense(units=1024, activation='relu')\n","        self.dp2 = tf.keras.layers.Dropout(0.4)\n","        self.fc3 = tf.keras.layers.Dense(units=num_classes, activation='softmax')\n","\n","    def import_w(self, model):\n","        self.conv1.import_w(model.layers[1].layers[0:8])\n","\n","        self.conv2_1.import_w(model.layers[1].layers[8:18-1])\n","        self.conv2_2.import_w(model.layers[1].layers[18:27-1])\n","        self.conv2_3.import_w(model.layers[1].layers[27:36-1])\n","\n","        self.conv3_1.import_w(model.layers[1].layers[36:46-1])\n","        self.conv3_2.import_w(model.layers[1].layers[46:55-1])\n","        self.conv3_3.import_w(model.layers[1].layers[55:64-1])\n","        self.conv3_4.import_w(model.layers[1].layers[64:73-1])\n","\n","        self.conv4_1.import_w(model.layers[1].layers[73:83-1])\n","        self.conv4_2.import_w(model.layers[1].layers[83:92-1])\n","        self.conv4_3.import_w(model.layers[1].layers[92:101-1])\n","        self.conv4_4.import_w(model.layers[1].layers[101:110-1])\n","        self.conv4_5.import_w(model.layers[1].layers[110:119-1])\n","        self.conv4_6.import_w(model.layers[1].layers[119:128-1])\n","\n","        self.conv5_1.import_w(model.layers[1].layers[128:138-1])\n","        self.conv5_2.import_w(model.layers[1].layers[138:147-1])\n","        self.conv5_3.import_w(model.layers[1].layers[147:156-1])\n","\n","        for i in range(len(self.bn.weights)):\n","            self.bn.weights[i].assign(model.layers[1].layers[156].weights[i])\n","\n","        for i in range(len(self.relu.weights)):\n","            self.relu.weights[i].assign(model.layers[1].layers[157].weights[i])\n","\n","        for i in range(len(self.pool.weights)):\n","            self.pool.weights[i].assign(model.layers[2].weights[i])\n","\n","        for i in range(len(self.fc1.weights)):\n","            self.fc1.weights[i].assign(model.layers[3].weights[i])\n","\n","        for i in range(len(self.dp1.weights)):\n","            self.dp1.weights[i].assign(model.layers[4].weights[i])\n","\n","        for i in range(len(self.fc2.weights)):\n","            self.fc2.weights[i].assign(model.layers[5].weights[i])\n","\n","        for i in range(len(self.dp2.weights)):\n","            self.dp2.weights[i].assign(model.layers[6].weights[i])\n","\n","        for i in range(len(self.fc3.weights)):\n","            self.fc3.weights[i].assign(model.layers[7].weights[i])\n","\n","    def call(self, x):\n","        x = self.Input(x)\n","        x = self.conv1(x)\n","        x = self.conv2_1(x)\n","        x = self.conv2_2(x)\n","        x = self.conv2_3(x)\n","        x = self.conv3_1(x)\n","        x = self.conv3_2(x)\n","        x = self.conv3_3(x)\n","        x = self.conv3_4(x)\n","        x = self.conv4_1(x)\n","        x = self.conv4_2(x)\n","        x = self.conv4_3(x)\n","        x = self.conv4_4(x)\n","        x = self.conv4_5(x)\n","        x = self.conv4_6(x)\n","        x = self.conv5_1(x)\n","        x = self.conv5_2(x)\n","        x = self.conv5_3(x)\n","\n","        x = self.bn(x)\n","        x = self.relu(x)\n","        x = self.pool(x)\n","\n","        x = self.fc1(x)\n","        x = self.dp1(x)\n","        x = self.fc2(x)\n","        x = self.dp2(x)\n","        x = self.fc3(x)\n","        return x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tVfWMKxsGe5b","executionInfo":{"status":"ok","timestamp":1667812382879,"user_tz":-180,"elapsed":908,"user":{"displayName":"Данила Курякин","userId":"05471251660353855023"}},"outputId":"6c870e33-0790-42e3-b750-955a45a5d10a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.9.2\n"]}]},{"cell_type":"code","source":["if not os.path.isdir('Models'):\n","    os.mkdir('Models')\n","\n","import json\n","with open('/content/Settings/Training_Settings.json') as json_file1:\n","    training_settings = json.load(json_file1)\n","with open('/content/Settings/LHC_Settings.json') as json_file2:\n","    lhc_settings = json.load(json_file2)\n","\n","Params = lhc_settings\n","\n","del lhc_settings\n","\n","seed = training_settings['seed']\n","\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","tf.random.set_seed(seed)\n","random.seed(seed)\n","np.random.seed(seed)\n","\n","path_val = \"/content/Data/data_val.csv\"\n","validation_imagesRGB, validation_labels = etl_data(path_val)\n","\n","Categories = ['Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise', 'Neutral']\n","\n","\n","\n","\n","ResNet34, preprocess_input = Classifiers.get('resnet34')\n","resnet_model = ResNet34(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","x = resnet_model.input\n","y = preprocess_input(x)\n","y = resnet_model(y)\n","y = tf.keras.layers.GlobalAveragePooling2D()(y)\n","y = tf.keras.layers.Dense(units=4096, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=3))(y)\n","y = tf.keras.layers.Dropout(rate=0.4)(y)\n","y = tf.keras.layers.Dense(units=1024, activation='relu', kernel_initializer=tf.keras.initializers.GlorotUniform(seed=4))(y)\n","y = tf.keras.layers.Dropout(rate=0.4)(y)\n","y = tf.keras.layers.Dense(units=7, activation='softmax')(y)\n","base_model = tf.keras.Model(inputs=x, outputs=y)\n","\n","model = LHC_ResNet34(input_shape=(224, 224, 3), num_classes=7, att_params=Params)\n","x0 = np.ones(shape=(10, 224, 224, 3), dtype='float32')\n","y0 = model(x0)\n","model.import_w(base_model)\n","\n","del x\n","del y\n","del base_model\n","del ResNet34\n","del preprocess_input\n","del resnet_model\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hRlA50d2GBcD","executionInfo":{"status":"ok","timestamp":1667812408775,"user_tz":-180,"elapsed":25899,"user":{"displayName":"Данила Курякин","userId":"05471251660353855023"}},"outputId":"eeecb86c-1a70-4d94-c422-c1dc7ba7caa9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000_no_top.h5\n","85521592/85521592 [==============================] - 1s 0us/step\n"]},{"output_type":"execute_result","data":{"text/plain":["5123"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rescale=None,\n","    rotation_range=training_settings['rotation_range'][0],\n","    width_shift_range=training_settings['width_shift_range'][0],\n","    height_shift_range=training_settings['height_shift_range'][0],\n","    shear_range=training_settings['shear_range'][0],\n","    zoom_range=training_settings['zoom_range'][0],\n","    horizontal_flip=training_settings['horizontal_flip'][0]\n",")\n","\n","train_generator = train_data_gen.flow_from_directory(\n","    directory='/content/Data_Images/Training',\n","    target_size=(224, 224),\n","    color_mode='rgb',\n","    classes=Categories,\n","    class_mode='categorical',\n","    batch_size=training_settings['batch_size'][0],\n","    seed=seed+1\n",")\n","\n","opt = tf.keras.optimizers.Adam(learning_rate=training_settings['learning_rate'][0],\n","                               beta_1=0.9,\n","                               beta_2=0.999,\n","                               epsilon=1e-07,\n","                               amsgrad=False,\n","                               name='Adam')\n","\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n","\n","callback1 = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', \n","                                             patience=training_settings['patience'][0], \n","                                             restore_best_weights=True)\n","callback2 = tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/Meta_dataset/Models', \n","                                               monitor='val_categorical_accuracy', \n","                                               verbose=1, \n","                                               save_best_only=True)\n","\n","for i in range(0,15):\n","  history = model.fit(\n","      train_generator,\n","      epochs=300,\n","      verbose=1,\n","      callbacks=[callback1, callback2],\n","      validation_data=(validation_imagesRGB, validation_labels)\n","  )\n","  model.save_weights(\"/content/drive/MyDrive/Meta_dataset/h5_model1\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ORYkr2vVW_p","outputId":"2b0b5cd7-bfdf-446f-8a80-dab8f934bedf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 28709 images belonging to 7 classes.\n","Epoch 1/300\n","599/599 [==============================] - ETA: 0s - loss: 1.8086 - categorical_accuracy: 0.2516"]}]},{"cell_type":"code","source":["# #  2.2\n","# train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n","#     rescale=None,\n","#     rotation_range=training_settings['rotation_range'][1],\n","#     width_shift_range=training_settings['width_shift_range'][1],\n","#     height_shift_range=training_settings['height_shift_range'][1],\n","#     shear_range=training_settings['shear_range'][1],\n","#     zoom_range=training_settings['zoom_range'][1],\n","#     horizontal_flip=training_settings['horizontal_flip'][1]\n","# )\n","\n","\n","# train_generator = train_data_gen.flow_from_directory(\n","#     directory='/content/Data_Images/Training',\n","#     target_size=(224, 224),\n","#     color_mode='rgb',\n","#     classes=Categories,\n","#     class_mode='categorical',\n","#     batch_size=training_settings['batch_size'][1],\n","#     seed=seed+1\n","# )"],"metadata":{"id":"3w3KxXY-U4Pt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# opt = tf.keras.optimizers.SGD(learning_rate=training_settings['learning_rate'][1])\n","\n","# model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n","\n","# callback1 = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=training_settings['patience'][1], restore_best_weights=True)\n","# callback2 = tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/Meta_dataset/Models', monitor='val_categorical_accuracy', verbose=1, save_best_only=True)\n","\n","# history2 = model.fit(\n","#     train_generator,\n","#     epochs=300,\n","#     verbose=1,\n","#     callbacks=[callback1, callback2],\n","#     validation_data=(validation_imagesRGB, validation_labels)\n","# )\n","# model.save_weights(\"/content/drive/MyDrive/Meta_dataset/h5_model2\")"],"metadata":{"id":"zRIaZo6XWBb5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #  3.2\n","# train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n","#     rescale=None,\n","# )\n","\n","\n","# train_generator = train_data_gen.flow_from_directory(\n","#     directory='/content/Data_Images/Training',\n","#     target_size=(224, 224),\n","#     color_mode='rgb',\n","#     classes=Categories,\n","#     class_mode='categorical',\n","#     batch_size=training_settings['batch_size'][2],\n","#     seed=seed+2\n","# )"],"metadata":{"id":"vA9FZTJ-U6U1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# opt = tf.keras.optimizers.SGD(learning_rate=training_settings['learning_rate'][2])\n","# model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n","\n","# callback1 = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=training_settings['patience'][2], restore_best_weights=True)\n","# callback2 = tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/Meta_dataset/Models', monitor='val_categorical_accuracy', verbose=1, save_best_only=True)\n","\n","\n","# history3 = model.fit(\n","#     train_generator,\n","#     epochs=300,\n","#     verbose=1,\n","#     callbacks=[callback1, callback2],\n","#     validation_data=(validation_imagesRGB, validation_labels)\n","# )\n","# model.save_weights(\"/content/drive/MyDrive/Meta_dataset/h5_model3\")"],"metadata":{"id":"WTFI4eTXWDME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","\n","tf.random.set_seed(0)\n","random.seed(0)\n","np.random.seed(0)\n","\n","\n","\n","# DATA IMPORT\n","Categories = ['Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise', 'Neutral']\n","\n","full_train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rescale=None\n",")\n","\n","full_train_generator = full_train_data_gen.flow_from_directory(\n","    directory='/content/Data_Images/Training',\n","    target_size=(224, 224),\n","    color_mode='rgb',\n","    classes=Categories,\n","    class_mode='categorical',\n","    batch_size=28709,\n","    shuffle=False\n",")\n","\n","h = full_train_generator.next()\n","training_imagesRGB = h[0]\n","training_labels = h[1]\n","\n","del h\n","gc.collect()\n","\n","path_val = \"/content/Data/data_val.csv\"\n","path_test = \"/content/Data/data_test.csv\"\n","validation_imagesRGB, validation_labels = etl_data(path_val)\n","testing_imagesRGB, testing_labels = etl_data(path_test)\n","\n","\n","\n","\n","\n","\n","\n","# MODEL IMPORT\n","Params = {'num_heads': [8, 8, 7, 7, 1],\n","          'att_embed_dim': [196, 196, 56, 14, 25],\n","          'kernel_size': [3, 3, 3, 3, 3],\n","          'pool_size': [3, 3, 3, 3, 3],\n","          'norm_c': [1, 1, 1, 1, 1]}\n","model = LHC_ResNet34(input_shape=(224, 224, 3), num_classes=7, att_params=Params)\n","x0 = np.ones(shape=(10, 224, 224, 3), dtype='float32')\n","y0 = model(x0)\n","model.load_weights('/content/drive/MyDrive/Meta_dataset/Models')\n","\n","\n","\n","#METRICS\n","print(\"LHC_Net Perf:\")\n","pred_train = model.predict(training_imagesRGB)\n","loss_train = tf.keras.losses.CategoricalCrossentropy()(training_labels, pred_train).numpy()\n","perf_train = tf.keras.metrics.CategoricalAccuracy(dtype='float64')(training_labels, pred_train).numpy()\n","print('Train Loss: ', '%.17f' % loss_train)\n","print('Train Perf: ', '%.17f' % perf_train)\n","pred_val = model.predict(validation_imagesRGB)\n","perf_val = tf.keras.metrics.CategoricalAccuracy(dtype='float64')(validation_labels, pred_val).numpy()\n","print('Val Perf: ', '%.17f' % perf_val)\n","pred_test = model.predict(testing_imagesRGB)\n","perf_test = tf.keras.metrics.CategoricalAccuracy(dtype='float64')(testing_labels, pred_test).numpy()\n","print('Test Perf: ', '%.17f' % perf_test)\n","pred_test_uniqueness = Check_Unique(pred_test)\n","print('Test Pred Repeated: ', pred_test_uniqueness)\n","\n","\n","\n","\n","# TTA\n","tf.config.run_functions_eagerly(True)\n","tta_pred_test = TTA_Inference(model, testing_imagesRGB)\n","tf.config.run_functions_eagerly(False)\n","\n","\n","\n","\n","\n","\n","\n","# METRICS TTA\n","tta_perf_test = tf.keras.metrics.CategoricalAccuracy(dtype='float64')(testing_labels, tta_pred_test).numpy()\n","print('TTA Test Perf: ', '%.17f' % tta_perf_test)\n","print(\"\")\n","tta_pred_test_uniqueness = Check_Unique(tta_pred_test)\n","print('TTA Test Pred Repeated: ', tta_pred_test_uniqueness)\n","print(\"\")\n","print(\"\")\n","print(\"\")"],"metadata":{"id":"kTQfeu2GNaad"},"execution_count":null,"outputs":[]}]}