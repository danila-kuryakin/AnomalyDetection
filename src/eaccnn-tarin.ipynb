{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport math\nimport cv2\nimport pickle\nimport random\nimport pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torchvision import transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-10T14:13:36.651492Z","iopub.execute_input":"2023-06-10T14:13:36.651870Z","iopub.status.idle":"2023-06-10T14:13:39.141069Z","shell.execute_reply.started":"2023-06-10T14:13:36.651790Z","shell.execute_reply":"2023-06-10T14:13:39.139140Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"resnet50_path = '/kaggle/input/eacdata/resnet50_ft_weight.pkl'\n\nTRAIN_CSV = pd.read_csv(\n    '/kaggle/input/rafmtcnndef/mtcnn_preprocess/train.csv',\n    sep=' ',\n)\n\nVAL_CSV = pd.read_csv(\n    '/kaggle/input/rafmtcnndef/mtcnn_preprocess/val.csv',\n    sep=' ',\n)\n\nTEST_CSV = pd.read_csv(\n    '/kaggle/input/rafmtcnndef/mtcnn_preprocess/test.csv',\n    sep=' ',\n)\n\nTRAIN_DIR = '/kaggle/input/rafmtcnndef/mtcnn_preprocess/train'\nVAL_DIR = '/kaggle/input/rafmtcnndef/mtcnn_preprocess/val'\nTEST_DIR = '/kaggle/input/rafmtcnndef/mtcnn_preprocess/test'\n\nworkers=2\nbatch_size=1\nw=7\nh=7\ngpu=0\nlam=5\nepochs = 100","metadata":{"execution":{"iopub.status.busy":"2023-06-10T14:13:39.147396Z","iopub.execute_input":"2023-06-10T14:13:39.148406Z","iopub.status.idle":"2023-06-10T14:13:39.202616Z","shell.execute_reply.started":"2023-06-10T14:13:39.148347Z","shell.execute_reply":"2023-06-10T14:13:39.201700Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def add_g(image_array, mean=0.0, var=30):\n    std = var ** 0.5\n    image_add = image_array + np.random.normal(mean, std, image_array.shape)\n    image_add = np.clip(image_add, 0, 255).astype(np.uint8)\n    return image_add\n\ndef flip_image(image_array):\n    return cv2.flip(image_array, 1)\n    \ndef generate_flip_grid(w, h, device):\n    # used to flip attention maps\n    x_ = torch.arange(w).view(1, -1).expand(h, -1)\n    y_ = torch.arange(h).view(-1, 1).expand(-1, w)\n    grid = torch.stack([x_, y_], dim=0).float().to(device)\n    grid = grid.unsqueeze(0).expand(1, -1, -1, -1)\n    grid[:, 0, :, :] = 2 * grid[:, 0, :, :] / (w - 1) - 1\n    grid[:, 1, :, :] = 2 * grid[:, 1, :, :] / (h - 1) - 1\n    grid[:, 0, :, :] = -grid[:, 0, :, :]\n    return grid","metadata":{"execution":{"iopub.status.busy":"2023-06-10T14:13:39.204173Z","iopub.execute_input":"2023-06-10T14:13:39.205217Z","iopub.status.idle":"2023-06-10T14:13:39.217139Z","shell.execute_reply.started":"2023-06-10T14:13:39.205178Z","shell.execute_reply":"2023-06-10T14:13:39.216130Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Dataset(data.Dataset):\n    def __init__(self,  df, data_dir, phase='test', transform=None):\n        self.df = df\n        self.data_dir = data_dir\n        self.transform = transform\n        self.aug_func = [flip_image, add_g]\n        self.phase = phase\n\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_name = f'{self.data_dir}/{self.df.iloc[index][\"name\"]}'\n        label = self.df.iloc[index][\"label\"]\n        \n        image = cv2.imread(img_name)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n           \n        image1 = image\n        image1 = self.aug_func[0](image)\n        \n\n        if self.phase == 'train':\n            if random.uniform(0, 1) > 0.5:\n                image = self.aug_func[1](image)\n        print(image.shape)\n\n        if self.transform is not None:\n            image = self.transform(image)\n            image1 = self.transform(image1)\n        print(image.shape)\n        \n        image1 = transforms.RandomHorizontalFlip(p=1)(image)\n\n        return image, label, index, image1","metadata":{"execution":{"iopub.status.busy":"2023-06-10T14:13:39.220534Z","iopub.execute_input":"2023-06-10T14:13:39.221278Z","iopub.status.idle":"2023-06-10T14:13:39.233531Z","shell.execute_reply.started":"2023-06-10T14:13:39.221239Z","shell.execute_reply":"2023-06-10T14:13:39.232696Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225]),\n        transforms.RandomErasing(scale=(0.02, 0.25)) ])\n    \n    \n    \n\ntrain_dataset = Dataset(TRAIN_CSV, TRAIN_DIR, 'train', train_transforms)\nout = train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-06-10T14:13:39.235161Z","iopub.execute_input":"2023-06-10T14:13:39.235912Z","iopub.status.idle":"2023-06-10T14:13:39.348855Z","shell.execute_reply.started":"2023-06-10T14:13:39.235873Z","shell.execute_reply":"2023-06-10T14:13:39.347751Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(311, 265, 3)\ntorch.Size([3, 224, 224])\n","output_type":"stream"}]},{"cell_type":"code","source":"class Flatten(nn.Module):\n    def forward(self, input):\n        return input.view(input.size(0), -1)\n    \n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=8631, include_top=True):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.include_top = include_top\n        \n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True)\n\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, \n                  return_indices=False, ceil_mode=False)\n        \n        \n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        \n        if not self.include_top:\n            return x\n        \n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-06-10T14:13:39.350330Z","iopub.execute_input":"2023-06-10T14:13:39.350727Z","iopub.status.idle":"2023-06-10T14:13:39.395043Z","shell.execute_reply.started":"2023-06-10T14:13:39.350687Z","shell.execute_reply":"2023-06-10T14:13:39.393089Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    \n    def __init__(self, pretrained=True, num_classes=7):\n        super(Model, self).__init__()\n        resnet50 = ResNet(Bottleneck, [3, 4, 6, 3])\n        with open(resnet50_path, 'rb') as f:\n            obj = f.read()\n        weights = {key: torch.from_numpy(arr) \n                   for key, arr in pickle.loads(obj, encoding='latin1').items()}\n        resnet50.load_state_dict(weights)\n        \n        self.features = nn.Sequential(*list(resnet50.children())[:-2])  \n        self.features2 = nn.Sequential(*list(resnet50.children())[-2:-1])  \n        self.fc = nn.Linear(2048, 7)  \n        \n        \n    def forward(self, x):        \n        x = self.features(x)\n        #### 1, 2048, 7, 7\n        feature = self.features2(x)\n        #### 1, 2048, 1, 1\n        \n        feature = feature.view(feature.size(0), -1)\n        output = self.fc(feature)\n        \n        params = list(self.parameters())\n        fc_weights = params[-2].data\n        fc_weights = fc_weights.view(1, 7, 2048, 1, 1)\n        fc_weights = Variable(fc_weights, requires_grad = False)\n\n        # attention\n        feat = x.unsqueeze(1) # N * 1 * C * H * W\n        hm = feat * fc_weights\n        hm = hm.sum(2) # N * self.num_labels * H * W\n\n        return output, hm","metadata":{"execution":{"iopub.status.busy":"2023-06-10T14:13:39.396878Z","iopub.execute_input":"2023-06-10T14:13:39.397577Z","iopub.status.idle":"2023-06-10T14:13:39.412123Z","shell.execute_reply.started":"2023-06-10T14:13:39.397530Z","shell.execute_reply":"2023-06-10T14:13:39.411202Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def ACLoss(att_map1, att_map2, grid_l, output):\n    flip_grid_large = grid_l.expand(output.size(0), -1, -1, -1)\n    flip_grid_large = Variable(flip_grid_large, requires_grad = False)\n    flip_grid_large = flip_grid_large.permute(0, 2, 3, 1)\n    att_map2_flip = F.grid_sample(att_map2, flip_grid_large, mode = 'bilinear', padding_mode = 'border', align_corners=True)\n    flip_loss_l = F.mse_loss(att_map1, att_map2_flip)\n    return flip_loss_l","metadata":{"execution":{"iopub.status.busy":"2023-06-10T14:13:39.413818Z","iopub.execute_input":"2023-06-10T14:13:39.414473Z","iopub.status.idle":"2023-06-10T14:13:39.426276Z","shell.execute_reply.started":"2023-06-10T14:13:39.414434Z","shell.execute_reply":"2023-06-10T14:13:39.425314Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, optimizer, scheduler, device):\n    running_loss = 0.0\n    iter_cnt = 0\n    correct_sum = 0\n    \n    model.to(device)\n    model.train()\n\n    total_loss = []\n    for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(train_loader):\n        imgs1 = imgs1.to(device)\n        imgs2 = imgs2.to(device)\n        labels = labels.to(device)\n\n\n        criterion = nn.CrossEntropyLoss(reduction='none')\n\n\n\n        output, hm1 = model(imgs1)\n        output_flip, hm2 = model(imgs2)\n        \n        grid_l = generate_flip_grid(w, h, device)\n        \n\n        loss1 = nn.CrossEntropyLoss()(output, labels)\n        flip_loss_l = ACLoss(hm1, hm2, grid_l, output)\n\n\n        loss = loss1 + lam * flip_loss_l\n\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n\n        iter_cnt += 1\n        _, predicts = torch.max(output, 1)\n        correct_num = torch.eq(predicts, labels).sum()\n        correct_sum += correct_num\n        running_loss += loss\n\n    scheduler.step()\n    running_loss = running_loss / iter_cnt\n    acc = correct_sum.float() / float(train_loader.dataset.__len__())\n    return acc, running_loss","metadata":{"execution":{"iopub.status.busy":"2023-06-10T14:13:39.427892Z","iopub.execute_input":"2023-06-10T14:13:39.428519Z","iopub.status.idle":"2023-06-10T14:13:39.441968Z","shell.execute_reply.started":"2023-06-10T14:13:39.428483Z","shell.execute_reply":"2023-06-10T14:13:39.440721Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def test(model, test_loader, device):\n    with torch.no_grad():\n        model.eval()\n\n        running_loss = 0.0\n        iter_cnt = 0\n        correct_sum = 0\n        data_num = 0\n\n\n        for batch_i, (imgs1, labels, indexes, imgs2) in enumerate(test_loader):\n            imgs1 = imgs1.to(device)\n            labels = labels.to(device)\n\n\n            outputs, _ = model(imgs1)\n\n\n            loss = nn.CrossEntropyLoss()(outputs, labels)\n\n            iter_cnt += 1\n            _, predicts = torch.max(outputs, 1)\n\n            correct_num = torch.eq(predicts, labels).sum()\n            correct_sum += correct_num\n\n            running_loss += loss\n            data_num += outputs.size(0)\n\n        running_loss = running_loss / iter_cnt\n        test_acc = correct_sum.float() / float(data_num)\n    return test_acc, running_loss","metadata":{"execution":{"iopub.status.busy":"2023-06-10T14:13:39.445697Z","iopub.execute_input":"2023-06-10T14:13:39.446330Z","iopub.status.idle":"2023-06-10T14:13:39.456585Z","shell.execute_reply.started":"2023-06-10T14:13:39.446295Z","shell.execute_reply":"2023-06-10T14:13:39.455583Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225]),\n        transforms.RandomErasing(scale=(0.02, 0.25)) ])\n    \nval_transforms = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])])\n    \n    \n\ntrain_dataset = Dataset(TRAIN_CSV, TRAIN_DIR, 'train', train_transforms)\nval_dataset = Dataset(TEST_CSV, TEST_DIR, val_transforms)    \n\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset,\n                                               batch_size=batch_size,\n                                               shuffle=True,\n                                               num_workers=workers,\n                                               pin_memory=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n                                              shuffle=False,\n                                              num_workers=workers,\n                                              pin_memory=True)\n    \n    \n    \n    \nmodel = Model()\n    \ndevice = torch.device('cuda:{}'.format(gpu))\nmodel.to(device)\n\noptimizer = torch.optim.Adam(model.parameters() , lr=0.0001, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n\n    \n   \n    \n    \nfor i in range(1, epochs + 1):\n    train_acc, train_loss = train(model, train_loader, optimizer, scheduler, device)\n    test_acc, test_loss = test(model, test_loader, device)\n    print('(Epoch: %d)Train acc: %f, Train loss: %f, Test acc: %f, Test loss: %f\\n'%(\n        i, train_acc, train_loss, test_acc, test_loss))\n    with open('rebuttal_50_noise_'+str(label_path)+'.txt', 'a') as f:\n        f.write(str(i)+'_'+str(test_acc)+'\\n')\n    if test_acc > 0.895:\n        torch.save({'iter': i,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(), },\n                    os.path.join('/kaggle/working/out', \"epoch\" + str(i) + \"_acc %f\"%(test_acc) + \".pth\"))\n        print('Model saved.')","metadata":{"execution":{"iopub.status.busy":"2023-06-10T14:13:39.458247Z","iopub.execute_input":"2023-06-10T14:13:39.458908Z","iopub.status.idle":"2023-06-10T14:13:53.189767Z","shell.execute_reply.started":"2023-06-10T14:13:39.458870Z","shell.execute_reply":"2023-06-10T14:13:53.188168Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"(339, 92, 3)\n(264, 214, 3)\ntorch.Size([3, 224, 224])\ntorch.Size([3, 224, 224])\n(222, 174, 3)\ntorch.Size([3, 224, 224])\n(426, 337, 3)\n(236, 190, 3)\ntorch.Size([3, 224, 224])\ntorch.Size([3, 224, 224])\n(161, 120, 3)\ntorch.Size([3, 224, 224])\n(148, 109, 3)\ntorch.Size([3, 224, 224])\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/src/pytorch/aten/src/ATen/native/cuda/Loss.cu:257: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_22/3964061899.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     print('(Epoch: %d)Train acc: %f, Train loss: %f, Test acc: %f, Test loss: %f\\n'%(\n","\u001b[0;32m/tmp/ipykernel_22/3746474166.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    220\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mforeach\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                                 \u001b[0mper_device_and_dtype_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.","output_type":"error"}]}]}